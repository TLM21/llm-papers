# llm-papers
  Best LLM papers

# Format 
  - [ Month/Year ] [ **Title **] [ PDF ] [ GIT ] [ Takeaway ] 

# Papers
  - [ 02/2024 ] [ **More Agents Is All You Need**] [ [ PDF ](https://arxiv.org/pdf/2402.05120v1) ] [ [ GIT ](https://anonymous.4open.science/r/more_agent_is_all_you_need/README.md) ] [ In this study, increasing instantiated LLM agents improves performance on complex tasks using a straightforward sampling-and-voting method. Performance gains vary with task difficulty, specifically inherent difficulty (I), reasoning step lengths (S), and prior probability (K). ] 

  - [ 06/2017 ] [ **Attention Is All You Need** ] [ [ PDF ](https://arxiv.org/pdf/1706.03762) ] [ [ GIT ](https://github.com/tensorflow/tensor2tensor) ] [ Authors introduce, Transformer model as the first sequence transduction system entirely reliant on attention mechanisms, eliminating the need for recurrent layers commonly found in encoder-decoder structures.] 
